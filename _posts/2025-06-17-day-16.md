---
layout: post
title: "Day 16 â€“ Day 16 of ceamls"
date: 2025-06-17
author: Ignatius Nwankwo
permalink: /day16.html
tags: ["Conda", "Organization"]

what_i_learned: |
  today I began testing efficientnet-b0v2 and b1v2. For B0V2, I used a batch size 40, epoch size 20, adamW optimizer and a dropout layer of .5 and global average pooling layer 2D in the base model architecture. I also increased the resolution of the training, testing and validation images to 224x224 to 260x260. The output actually turned out to be worse, but gave me an idea of how to better change the parameters.
I then ran v2b1 on two seperate computers.  For the first trial I kept most of the features from V2B0, but for the second trial I changed the input size back to 224x224, removed teh dropout and pooling layers, and changed both epoch and batch size to 32. 


blockers: |
  i had to work on both my work pc and my personal laptop to train models simultaneously and save time. I also ran into admin restrictions on my work pc and had to work around those. Lastly I ran into organizational issues where I mismatched file names.

reflection: |
  im learning more about file management and slowly gaining confidence in my organizational skills. I'm practicing more with various command shells and comparing my workflow with others. I'm also able to strengthen my problem solving and communication skills, as well as efficiency. I hope to play around with the parameters more tomorrow and try the heavier models later on.


---
