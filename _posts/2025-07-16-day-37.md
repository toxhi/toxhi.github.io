---
layout: post
title: "Day 37 â€“ Day 37 of ceamls"
date: 2025-07-16
author: Ignatius Nwankwo
permalink: /day37.html
tags: ["Model Checkpoint", "Revision"]

what_i_learned: |  
  this morning was mostly spent retraining my b5 model based on the hyperparameters I got from Optuna which gave me issues yesterday becuase I have to remove the model checkpoint. It appears something happened yesterday while I was gone that interrupted the training process so I had to restart it this morning so hopefully itll be done by the end of the day. I made some minor edits to the research paper and transferred a new dataset from an external hard drive into my computer that we hope to test. i also downloaded anaconda onto my laptop to potentially run models on google colab locally there. Update: I got my training results back and i was pretty impressed with what I got: [[2754  599] [ 974 1944]] Per-class accuracy: Drowsy: 82.135%, Non drowsy: 66.621% 

blockers: |
  the process of transferring the dataset took longer than expected becuase of how large it is and connecting the hard drive made my computer run much slower than usual.

reflection: |
  I noticed that making small effforts consistently allows me to be more productive and simplifies tasks as opposed to putting alot of pressure on myself to get alot done in a single moment which is unrealistic. After im done training b4 using the latest hyperparameters I got using Optuna, I will try out a new dataset proposed by one of my labmates. I will also reserach some diagrams I could use to describe my efficientnet model, as well as even try to develop my own diagram if I don't see one on the internet that accurately resembles the one I built. This will require me to study up on my model architecture, and perhaps end up citing more sources, but so far, this has been refreshing.
---
